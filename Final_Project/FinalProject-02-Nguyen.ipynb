{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144ad461",
   "metadata": {},
   "source": [
    "# Elle Nguyen - Section 02\n",
    "## Final Project: Prediction Model of COVID-19 Case Surveillance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df540396",
   "metadata": {},
   "source": [
    "### Importing required Python Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1847d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import xgboost as xgb\n",
    "from datetime import timedelta\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, mean_absolute_error, mean_squared_error, precision_recall_fscore_support, classification_report, confusion_matrix, roc_curve, auc   \n",
    "from statsmodels.tsa.api import Holt, SimpleExpSmoothing, ExponentialSmoothing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import stats\n",
    "from random import shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2348b8",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d6d90a",
   "metadata": {},
   "source": [
    "Load data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe53097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('COVID-19_Case_Surveillance_Public_Use_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac116b8",
   "metadata": {},
   "source": [
    "Check whether there are missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb33527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cdc_case_earliest_dt              0\n",
       "cdc_report_dt               8645152\n",
       "pos_spec_dt                53798621\n",
       "onset_dt                   59881586\n",
       "current_status                    0\n",
       "sex                               7\n",
       "age_group                        56\n",
       "race_ethnicity_combined           7\n",
       "hosp_yn                           0\n",
       "icu_yn                            0\n",
       "death_yn                          0\n",
       "medcond_yn                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc2bd2",
   "metadata": {},
   "source": [
    "Check whether there are categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c4af823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96649487 entries, 0 to 96649486\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Dtype \n",
      "---  ------                   ----- \n",
      " 0   cdc_case_earliest_dt     object\n",
      " 1   cdc_report_dt            object\n",
      " 2   pos_spec_dt              object\n",
      " 3   onset_dt                 object\n",
      " 4   current_status           object\n",
      " 5   sex                      object\n",
      " 6   age_group                object\n",
      " 7   race_ethnicity_combined  object\n",
      " 8   hosp_yn                  object\n",
      " 9   icu_yn                   object\n",
      " 10  death_yn                 object\n",
      " 11  medcond_yn               object\n",
      "dtypes: object(12)\n",
      "memory usage: 8.6+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059d9c1",
   "metadata": {},
   "source": [
    "There are 96,649,487 total entries. The highest missing values recorded is 59,881,586 which is more than 50% of the total entries; therefore, it is necessary to drop 2 columns pos_spec_dt and onset_dt due to having too many missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b9c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['pos_spec_dt', 'onset_dt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df5a3f",
   "metadata": {},
   "source": [
    "Dropping rows having at least 1 missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7407520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53cb52c",
   "metadata": {},
   "source": [
    "Take a look at the last 4 columns hosp_yn, icu_yn, death_yn, and medcond_yn that have some assigned entries as 'Missing' and 'Unknown'. A new dataframe will store these unknown values for predictions at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb614c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = df[df['death_yn'].isin(['Missing', 'Unknown'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71654ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.to_csv('data_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea533b74",
   "metadata": {},
   "source": [
    "Then remove these rows for data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.isin(['Missing', 'Unknown']).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfe7b7",
   "metadata": {},
   "source": [
    "Last dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc96157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cfe2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8cde21",
   "metadata": {},
   "source": [
    "The current data frame is now carefully filtered and processed to get rid of all missing values. It will be stored into a new csv file to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41310b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_covid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca808ae5",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d802463",
   "metadata": {},
   "source": [
    "Load new data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cab311",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('preprocessed_covid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa5a13c",
   "metadata": {},
   "source": [
    "The filtered data frame now has 1,222,658 rows and 10 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74753774",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbce819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "new_df['current_status'].value_counts().plot(kind='barh', width=0.5)\n",
    "plt.title('Case Status')\n",
    "plt.xlabel('Number of Cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7e7d9",
   "metadata": {},
   "source": [
    "As shown in the graph above, most of the cases are confirmed by laboratory testings while the remaining have had a confirmatory test performed but has a positive antigen test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['current_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7ba38",
   "metadata": {},
   "source": [
    "Based on the second pie chart for age_group, most of the confirmed cases come from the 50-59 years (13.6%) and the 0-9 years occupy the least percentage of 6.1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing 2 columns sex and age_group\n",
    "combined_cols = new_df.columns[3:5]\n",
    "\n",
    "# Draw a pie plot for each column\n",
    "for col in combined_cols:\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    new_df[col].value_counts().plot(kind='pie', autopct='%1.1f%%', fontsize=10, title='', ylabel='')\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc904edd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "new_df['race_ethnicity_combined'].value_counts().plot(kind='bar', width=0.5)\n",
    "plt.title('Race and Ethnicity')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Number of Cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18359e04",
   "metadata": {},
   "source": [
    "Most cases also do not have any medical backgrounds, never been hospitalized nor admitted to the ICU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90970e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the columns to plot\n",
    "cols = ['hosp_yn', 'icu_yn', 'medcond_yn']\n",
    "\n",
    "# Calculate the occurrences for each category in each column\n",
    "counts = new_df[cols].apply(pd.Series.value_counts)\n",
    "\n",
    "# Transpose the DataFrame to have the categories as the index and the columns as the dates\n",
    "counts = counts.T\n",
    "\n",
    "# Create the plot\n",
    "ax = counts.plot(kind='barh', stacked=True, figsize=(8, 4))\n",
    "\n",
    "# Set the title and axis labels\n",
    "ax.set_title('Medical Records')\n",
    "ax.set_xlabel('Number of Cases')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53360e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "new_df['death_yn'].value_counts().plot(kind='pie', autopct='%1.1f%%', fontsize=10, title='', ylabel='')\n",
    "plt.title('Death Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f398f4bc",
   "metadata": {},
   "source": [
    "With a small death percentage of 5.7% with 69,719 death cases, it can be concluded that most people without a medical background or any underlying presence of disease are found to be recovering from COVID-19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbf0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['death_yn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f24c7e3",
   "metadata": {},
   "source": [
    "### Datewise Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6fe19",
   "metadata": {},
   "source": [
    "Converting the first 2 columns cdc_case_earliest_dt and cdc_report_dt to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d207add",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['cdc_case_earliest_dt '] = pd.to_datetime(new_df['cdc_case_earliest_dt '], format='%d-%m-%Y', infer_datetime_format=True)\n",
    "new_df['cdc_case_earliest_dt '] = new_df['cdc_case_earliest_dt '].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "new_df['cdc_report_dt'] = pd.to_datetime(new_df['cdc_report_dt'], format='%d-%m-%Y', infer_datetime_format=True)\n",
    "new_df['cdc_report_dt'] = new_df['cdc_report_dt'].dt.strftime('%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeea86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4331310f",
   "metadata": {},
   "source": [
    "Sorting the first column cdc_case_earliest_dt in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7141a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.sort_values(by='cdc_case_earliest_dt ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce59506",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of Confirmed Cases: {len(new_df['cdc_case_earliest_dt '])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ccc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_cases(new_df):\n",
    "    # Convert date columns to datetime format\n",
    "    new_df['cdc_case_earliest_dt '] = pd.to_datetime(new_df['cdc_case_earliest_dt '], format='%d-%m-%Y', infer_datetime_format=True)\n",
    "    new_df['cdc_report_dt'] = pd.to_datetime(new_df['cdc_report_dt'], format='%d-%m-%Y')\n",
    "\n",
    "    # Group by month and count cases\n",
    "    cases_by_month = new_df.groupby(new_df['cdc_case_earliest_dt '].dt.to_period('M')).size()\n",
    "\n",
    "    # Plot line graph\n",
    "    plt.plot(cases_by_month.index.to_timestamp(), cases_by_month.values)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Number of Cases')\n",
    "    plt.title('Total Cases by Month')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8175773e",
   "metadata": {},
   "source": [
    "The below graph is right-skewed distribution (the concentration of data points towards the right tail more than the left tail). This indicates that most positive cases were detected towards the end of 2020 (around the months October and November of 2020). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92acaa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_cases(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_cases(new_df):\n",
    "    # Convert date columns to datetime format\n",
    "    new_df['cdc_case_earliest_dt '] = pd.to_datetime(new_df['cdc_case_earliest_dt '], format='%d-%m-%Y', infer_datetime_format=True)\n",
    "    new_df['cdc_report_dt'] = pd.to_datetime(new_df['cdc_report_dt'], format='%d-%m-%Y')\n",
    "    \n",
    "    # Group by year and count cases\n",
    "    cases_by_year = new_df.groupby(new_df['cdc_case_earliest_dt '].dt.year)['cdc_case_earliest_dt '].count()\n",
    "    \n",
    "    # Plot line graph\n",
    "    plt.plot(cases_by_year.index, cases_by_year.values)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Cases')\n",
    "    plt.title('Total Cases by Year')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69207fea",
   "metadata": {},
   "source": [
    "Looking at the cases year-wise, the graph has a descending trend line with a negative slope. The highest number of cases were reported in 2020 and significantly decreased since then with almost none reported in 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16972807",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yearly_cases(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd67f5",
   "metadata": {},
   "source": [
    "### Label Encoder: Converting all categorical features to numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad5d99",
   "metadata": {},
   "source": [
    "After applying Label Encoder to 8 categorical columns, the categories are listed as:  \n",
    "**1. current_status**  \n",
    "> Laboratory-confirmed case = 0  \n",
    "> Probable Case = 1  \n",
    "\n",
    "**2. sex**  \n",
    "> Female = 0  \n",
    "> Male = 1  \n",
    "> Other = 2  \n",
    "\n",
    "**3. age_group**  \n",
    "> 0 - 9 Years = 0  \n",
    "> 10 - 19 Years = 1  \n",
    "> 20 - 29 Years = 2  \n",
    "> 30 - 39 Years = 3  \n",
    "> 40 - 49 Years = 4  \n",
    "> 50 - 59 Years = 5  \n",
    "> 60 - 69 Years = 6  \n",
    "> 70 - 79 Years = 7  \n",
    "> 80 - 89 Years = 8  \n",
    "\n",
    "**4. race_ethnicity_combined**  \n",
    "> American Indian/Alaska Native, Non-Hispanic = 0  \n",
    "> Asian, Non-Hispanic = 1  \n",
    "> Black, Non-Hispanic = 2  \n",
    "> Hispanic/Latino = 3  \n",
    "> Multiple/Other, Non-Hispanic = 4  \n",
    "> Native Hawaiian/Other Pacific Islander, Non-Hispanic = 5  \n",
    "> White, Non-Hispanic = 6  \n",
    "\n",
    "**5. hosp_yn, icu_yn, death_yn, medcond_yn**  \n",
    "> No = 0  \n",
    "> Yes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30757c82",
   "metadata": {},
   "source": [
    "Apply label encoding to all columns except for the first 2 date columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "for col in new_df.columns[2:]:\n",
    "    new_df[col] = labelencoder.fit_transform(new_df[col])\n",
    "    print(col, labelencoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d68cbe",
   "metadata": {},
   "source": [
    "### Logistic Regression model for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c3c1d",
   "metadata": {},
   "source": [
    "**Since the goal is to build the survival prediction model, logistic regression is used to predict death_yn as a binary classification model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043539aa",
   "metadata": {},
   "source": [
    "Store the new dataframe without the first 2 date columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62aba24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_df = new_df.iloc[:, -8:]\n",
    "lr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd4c4e",
   "metadata": {},
   "source": [
    "Store the converted dataframe into a new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b81b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df.to_csv('encoded_covid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dafeda",
   "metadata": {},
   "source": [
    "Split the preprocessed dataset into 76% training set and 24% testing set in order to use 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lr_df.drop('death_yn', axis=1).values\n",
    "y = lr_df['death_yn'].values\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.24, \n",
    "                                                            random_state=0)\n",
    "\n",
    "print(\"train_val: {}, test: {}\".format(X_train_val.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80302e40",
   "metadata": {},
   "source": [
    "Normalize features using Min-Max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f12b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "X_train_val = normalizer.fit_transform(X_train_val)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40a9271",
   "metadata": {},
   "source": [
    "Train the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60853ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 10-fold cross-validation to select the hyperparameter λ\n",
    "folds = 10\n",
    "\n",
    "# Get the number of samples in the training and validation set\n",
    "num_train_val = X_train_val.shape[0] \n",
    "\n",
    "# Shuffle the index of samples in the train_val set\n",
    "index_of_samples = np.arange(num_train_val) \n",
    "shuffle(index_of_samples)\n",
    "\n",
    "# Split the index of the train_valid set into 10 folds\n",
    "index_of_folds = index_of_samples.reshape(folds, -1)\n",
    "index_of_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17fe727",
   "metadata": {},
   "source": [
    "Select the best hyperparameter with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e0886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search λ\n",
    "regularization_coefficient = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 50, 100]\n",
    "\n",
    "best_acc = 0.0\n",
    "best_reg = 0.0\n",
    "\n",
    "for reg in regularization_coefficient:\n",
    "    \n",
    "    # 10-fold cross-validation\n",
    "    sum_acc = 0.0\n",
    "    \n",
    "    for fold in range(folds):\n",
    "        \n",
    "        index_of_folds_temp = index_of_folds.copy()\n",
    "        \n",
    "        valid_index = index_of_folds_temp[fold,:].reshape(-1) # Get the index of the validation set\n",
    "        train_index = np.delete(index_of_folds_temp, fold, 0).reshape(-1) # Get the index of the training set\n",
    "        \n",
    "        # Training set\n",
    "        X_train = X_train_val[train_index]\n",
    "        y_train = y_train_val[train_index]\n",
    "        \n",
    "        # Validation set\n",
    "        X_valid = X_train_val[valid_index]\n",
    "        y_valid = y_train_val[valid_index]\n",
    "                \n",
    "        # Build the model with different hyperparameters\n",
    "        clf = LogisticRegression(penalty='l2', C=reg, solver='lbfgs')\n",
    "        \n",
    "        # Train the model with the training set\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_valid_pred = clf.predict(X_valid)\n",
    "        acc = accuracy_score(y_valid, y_valid_pred)\n",
    "        \n",
    "        sum_acc += acc\n",
    "    \n",
    "    cur_acc = sum_acc / folds\n",
    "    \n",
    "    print(\"reg_coeff: {}, acc: {:.3f}\".format(1.0/reg, cur_acc))\n",
    "    \n",
    "    # Store the best hyperparameter\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        best_reg = reg\n",
    "\n",
    "print(\"The best hyperparameter is {}\".format(best_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3ac2e",
   "metadata": {},
   "source": [
    "Retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l2', C=best_reg, solver='lbfgs')\n",
    "clf.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590eded",
   "metadata": {},
   "source": [
    "Evaluate the learned model on the testing set with accuracy, recall, precision, F1 score, and ROC_AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82167da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"accuracy: {:.5f}, recall: {:.5f}, precision: {:.5f}, f1: {:.5f}, roc_auc: {:.5f}\".format(acc, recall, precision, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f3ae8",
   "metadata": {},
   "source": [
    "**Conclusion:**  \n",
    "> Accuracy (0.955) means that 95.5% of the predictions were correct.  \n",
    "> Recall (0.446) identified 44.6% of the actual positive cases.  \n",
    "> Precision (0.661) means that when the model predicted a positive case, it was correct 66.1% of the time.  \n",
    "> F1 score (0.533) indicates an average overall model performance. Higher values yield better performance.  \n",
    "\n",
    "**These values suggest that the model has a high accuracy, but relatively low recall, precision, and F1 score. This means that the model is good at predicting negative cases, but not as good at predicting positive cases. Such performance aligns with the imbalanced data distribution: 94.3% recover from COVID while 5.7% actually died.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991b83b",
   "metadata": {},
   "source": [
    "Create an empty dataframe to store the performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 score', 'ROC_AUC score'])\n",
    "\n",
    "results = results.append({'Model': 'Logistic Regression', \n",
    "                          'Accuracy': acc, \n",
    "                          'Precision': precision, \n",
    "                          'Recall': recall, \n",
    "                          'F1 score': f1, \n",
    "                          'ROC_AUC score': roc_auc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a570d012",
   "metadata": {},
   "source": [
    "Visualize the importance of each model parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.title(\"Learned model parameter vector w\")\n",
    "columns_to_plot = [col for col in lr_df.columns[:] if col != 'death_yn']\n",
    "plt.bar(columns_to_plot, clf.coef_[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3d842b",
   "metadata": {},
   "source": [
    "The absolute magnitude of each model parameter corresponds to the strength of the relationship between that feature and the target variable. Large absolute values indicate that those features have a strong influence on the predicted outcome such as **age_group** and **hosp_yn**. It's easy to predict who is likely to die from COVID based on these data because such learned vectors hugely impact our prediction. On the other hand, small absolute values indicate that the corresponding features have little to no effect on the outcome such as **current_status** and **sex** - these features do not relate to the disease, thus hard to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.title(\"Absolute Learned model parameter vector w\")\n",
    "columns_to_plot = [col for col in lr_df.columns[:] if col != 'death_yn']\n",
    "plt.bar(columns_to_plot, abs(clf.coef_[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495be5a4",
   "metadata": {},
   "source": [
    "Due to a bad performance of logistic regression, it's necessary to switch to other prediction models to yield better outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc09b0",
   "metadata": {},
   "source": [
    "### Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd9b5a",
   "metadata": {},
   "source": [
    "According to Logistic Regression performance alone, its relatively low recall, precision, and F1 score align with the imbalanced dataset. Therefore, SMOTE is used for data augmentation for the minority class (which is the positive case in this dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e050273",
   "metadata": {},
   "source": [
    "Apply SMOTE to oversample the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f401a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e2b391",
   "metadata": {},
   "source": [
    "Normalize the features using Min-Max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c877645",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res = normalizer.fit_transform(X_train_res)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc340503",
   "metadata": {},
   "source": [
    "Retrain the logistic regression model on the resampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21bc66",
   "metadata": {},
   "source": [
    "Evaluate the model on the testing set with accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ce1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"accuracy: {:.5f}, recall: {:.5f}, precision: {:.5f}, f1: {:.5f}, roc_auc: {:.5f}\".format(acc, recall, precision, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340b8623",
   "metadata": {},
   "source": [
    "Store the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append({'Model': 'Logistic Regression with SMOTE', \n",
    "                          'Accuracy': acc, \n",
    "                          'Precision': precision, \n",
    "                          'Recall': recall, \n",
    "                          'F1 score': f1, \n",
    "                          'ROC_AUC score': roc_auc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87637fd",
   "metadata": {},
   "source": [
    "Get the confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79c3c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
    "report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", confusion_mat)\n",
    "print(\"Classification report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b992874",
   "metadata": {},
   "source": [
    "Visualize ROC curve and AUC (Area under ROC curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cf1dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c186940",
   "metadata": {},
   "source": [
    "AUC is approximately 1.0, indicating a good model performance. However, the precision score on Class 1 is still relatively low; therefore, it is neccesary to test out other models then compare each performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902baef2",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5859304",
   "metadata": {},
   "source": [
    "Split into training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed84b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.24, \n",
    "                                                            random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226a0c4",
   "metadata": {},
   "source": [
    "Normalize the features using Min-Max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0535c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = normalizer.fit_transform(X_train_val)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0ba0f",
   "metadata": {},
   "source": [
    "Train the decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18189c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "dtc.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18593818",
   "metadata": {},
   "source": [
    "Evaluate the model on the testing set with accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = dtc.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"accuracy: {:.5f}, recall: {:.5f}, precision: {:.5f}, f1: {:.5f}, roc_auc: {:.5f}\".format(acc, recall, precision, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54081fb",
   "metadata": {},
   "source": [
    "Store the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae57ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append({'Model': 'Decision Tree', \n",
    "                          'Accuracy': acc, \n",
    "                          'Precision': precision, \n",
    "                          'Recall': recall, \n",
    "                          'F1 score': f1, \n",
    "                          'ROC_AUC score': roc_auc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9234c460",
   "metadata": {},
   "source": [
    "Apply SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc40240",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res, y_train_res = smote.fit_resample(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfd6ad",
   "metadata": {},
   "source": [
    "Normalize the features using Min-Max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res = normalizer.fit_transform(X_train_res)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d9ea0",
   "metadata": {},
   "source": [
    "Retrain using the decision tree model on the resampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "dtc.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8062a092",
   "metadata": {},
   "source": [
    "Evaluate the model on the testing set with accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccd8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = dtc.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"accuracy: {:.5f}, recall: {:.5f}, precision: {:.5f}, f1: {:.5f}, roc_auc: {:.5f}\".format(acc, recall, precision, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f66c26",
   "metadata": {},
   "source": [
    "Store the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b073d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append({'Model': 'Decision Tree with SMOTE', \n",
    "                          'Accuracy': acc, \n",
    "                          'Precision': precision, \n",
    "                          'Recall': recall, \n",
    "                          'F1 score': f1, \n",
    "                          'ROC_AUC score': roc_auc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3122f371",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d374858",
   "metadata": {},
   "source": [
    "Split into training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.24, \n",
    "                                                            random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec4fcbe",
   "metadata": {},
   "source": [
    "Normalize the feature using Min-Max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe41e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = normalizer.fit_transform(X_train_val)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96dd398",
   "metadata": {},
   "source": [
    "Create and train a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbfda30",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rfc.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb433896",
   "metadata": {},
   "source": [
    "Evaluate the model on the testing set with accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3907c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rfc.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"accuracy: {:.5f}, recall: {:.5f}, precision: {:.5f}, f1: {:.5f}, roc_auc: {:.5f}\".format(acc, recall, precision, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac9ea4",
   "metadata": {},
   "source": [
    "Store the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce3a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append({'Model': 'Random Forest', \n",
    "                          'Accuracy': acc, \n",
    "                          'Precision': precision, \n",
    "                          'Recall': recall, \n",
    "                          'F1 score': f1, \n",
    "                          'ROC_AUC score': roc_auc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff538b02",
   "metadata": {},
   "source": [
    "Apply SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02dc931",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res, y_train_res = smote.fit_resample(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b50ec4",
   "metadata": {},
   "source": [
    "Normalize the features using Min-Max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res = normalizer.fit_transform(X_train_res)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e9c52",
   "metadata": {},
   "source": [
    "Retrain using the Random Forest model on the resampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rfc.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb7e71",
   "metadata": {},
   "source": [
    "Evaluate the model on the testing set with accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = dtc.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"accuracy: {:.5f}, recall: {:.5f}, precision: {:.5f}, f1: {:.5f}, roc_auc: {:.5f}\".format(acc, recall, precision, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21edaea7",
   "metadata": {},
   "source": [
    "Store the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eaf8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append({'Model': 'Random Forest with SMOTE', \n",
    "                          'Accuracy': acc, \n",
    "                          'Precision': precision, \n",
    "                          'Recall': recall, \n",
    "                          'F1 score': f1, \n",
    "                          'ROC_AUC score': roc_auc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2e5619",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c68d5",
   "metadata": {},
   "source": [
    "Split into training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.24, \n",
    "                                                            random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7875b7",
   "metadata": {},
   "source": [
    "Normalize the features using Min-Max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce869cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = normalizer.fit_transform(X_train_val)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd8476",
   "metadata": {},
   "source": [
    "Convert data to DMatrix format for XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38542e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_val, label=y_train_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893504b2",
   "metadata": {},
   "source": [
    "Set parameters for XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a24eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'eval_metric': 'logloss',\n",
    "    'verbosity': 0,\n",
    "    'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24472aac",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 100\n",
    "bst = xgb.train(params, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58414e30",
   "metadata": {},
   "source": [
    "Evaluate the model on the testing set with accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e5a73",
   "metadata": {},
   "source": [
    "Convert predicted probabilities to binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_binary = [1 if p >= 0.5 else 0 for p in y_test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a405094",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_test_pred_binary)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_test_pred_binary, average='binary')\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_binary)\n",
    "\n",
    "print(\"accuracy: %.5f%%\" % (acc * 100.0))\n",
    "print(\"precision: %.5f\" % precision)\n",
    "print(\"recall: %.5f\" % recall)\n",
    "print(\"f1 score: %.5f\" % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e230d24",
   "metadata": {},
   "source": [
    "Store the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96265ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append({'Model': 'XGBoost', \n",
    "                          'Accuracy': acc, \n",
    "                          'Precision': precision, \n",
    "                          'Recall': recall, \n",
    "                          'F1 score': f1, \n",
    "                          'ROC_AUC score': roc_auc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e0362c",
   "metadata": {},
   "source": [
    "### Model Performance Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42529052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6415697d",
   "metadata": {},
   "source": [
    "Sort in ascending order to get the highest prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068fc192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.sort_values('Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13cee1f",
   "metadata": {},
   "source": [
    "### Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d3ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
